先从我们熟知 Java 是如何实现并发的.

在 Java 中实现并发有三种方式.

1.volatile

2.synchronized

3.lock

volatile 的语义是什么了？
1.进制指令重排
2.对内存可见(volatile 关键字修饰的变量对其他线程可见)

那 volatile 在计算机的底层是如何实现的了？

1.volatile 关键字修饰的变量在转成汇编的时候会多出 lock 前缀的指令，lock 前缀的指令在多核处理器下会发生两件事：
(1)将当前缓存行中的数据写会到主存
(2)这个写会操作会使其他CPU缓存了该内存地址的数据无效.

计算机为了提高速度，每个 CPU 内部都有一级缓存、二级缓存，通过缓存和主存打交道, 这个和 JMM 内存模型很像，JMM 模型就是每个线程都有一个工作
内存，工作内存中存放主存中变量的拷贝，工作内存和主存打交道.

现在有一个问题：

如果多 CPU 缓存了同一个变量的值，那么一个 CPU 修改了一个变量的值，如果另一个 CPU 还是持有原值的话，那么这次修改是不是无意义？

前人还是聪明的，通过缓存一致性协议保证各个处理器中的缓存是一致的. 具体做法是每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是否不过期的，
如果当前处理器发现自己缓存行中的一个的内存地址被修改了，就会将当前缓存行设置成无效状态.

对于缓存一致性协议的实现，有些计算机采用总线锁，当一个处理器在总线上输出该信号，其他处理器的请求将被阻塞，代价较大.
还有一种实现是缓存锁定的方式：MESI

缓存一致性协议：MESI

M：被修改了(仅在本 CPU 中缓存了，和内存中的数据不一致)
E：独占(仅在本 CPU 中缓存了，且数据和内存中的数据一致)
S：共享(在多个 CPU 中都有缓存，且与内存中的数据一致)
I：无效(要么已经不再缓存中了，要么该缓存过时了)

M：一个处于M状态的缓存行，必须时刻监听所有读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作前把缓存行写会到主存，并把状态变为 S
E：一个处于E状态的缓存行，必须时刻监听试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把 E 状态设置为 S
S：一个处于S状态的缓存行，必须时刻监听使该缓存行无效或独占该缓存行的操作，如果监听到，则标记该缓存行为 I

只有对 M、E 进行写操作不需要额外的操作，如果对 S 状态缓存行进行写操作，则必须先发送一个 RFO 请求广播，
该广播可以让其他CPU的缓存中的相同数据的字段失效，即变成I状态.

这里会有一个表格：


                    远程读                             远程写                         本地读                     本地写
M  对M状态的缓存进行远程读，首先会将本地缓存刷新到主存中，  先把本地缓存刷新到主存，然后远程的
   然后远程的 CPU 从主存中读取数据，最后两个缓存行中的数据  CPU 在读取并写入，本地缓存状态变为
   都会变为 S 状态                                     I，远程缓存变为 M
E
S
I

针对这个问题，所以会有一些优化，就是通过填充技术，使得频繁修改的两个变量位于不同的缓存行. 例如 JDK7 的 LinkedTransferQueue 队列中的 
head 和 tail 节点，通过填充，凑足 64KB，让 head 和 tail 位于不同的缓存行，提高并发效率.

为什么要这么干了？

1.首先 inter 的 cpu 是不支持部分填充的，只能一次填充 64 KB 的数据.
2.如果不这么干，一旦 head 和 tail 节点位于同一个缓存行时，当多个 CPU 入队出队操作时，需要频繁的修改这两个指针，而这两个指针位于同一缓存行,
那么每次只能有一个 CPU 能够进行修改，所以并没有达到并发的效果，无声的性能杀手.

但是现在的编译器越来越智能了，它能在编译器就将无用的填充字段优化掉，所以需要通过其他手段来达到填充效果.


然后说下 synchronized 的实现：

1.synchronized 修饰分为同步方法和同步代码块，同步方法的实现是通过 monitorenter 和 monitorexit 指令来实现的，同步方法是通过一个标志位来
实现的.

synchronized 用的锁存放在 Java 对象头中，如果对象头是三个字节的数组，则虚拟机用三个字宽来存储对象头，否则用两个字宽来存储对象头.

JDK1.6 以前都说 synchronized 是重量级锁，在 1.6 的时候，JDK 对 synchronized 做了大量优化，就有了偏向锁，轻量级锁，重量级锁.
先说下这三种的使用场景：偏向锁用于只有一个线程的情况，没有竞争；轻量级锁用于线程竞争时间极短；重量级锁用于竞争时间长.

这些应用场景不是拍脑袋瞎说了，背后有一定的道理.

偏向锁：当一个线程访问同步代码块并获取锁时，会在对象头和栈帧中的锁记录中存储锁偏向的线程ID，以后该线程再获取锁的时候，只需要测试下对象头中
是否存储了指向当前线程的偏向锁即可. 如果测试成功，则获取锁，否则在测试下是否有偏向锁标记，没有设置，则采用 CAS竞争锁，如果设置了，则使用CAS
将对象头的偏向锁指向当前线程.

偏向锁使用了一种等到出现线程竞争的时候才会释放锁. 根据锁对象是否被锁定的状态，来确定撤销偏向锁后恢复到未锁定状态还是轻量级锁状态.

对于轻量级锁，线程会在执行同步块之前，JVM 会先在当前线程的栈帧中创建用于存储锁记录的空间，并将对象头中的 Mark Word 复制到锁记录中，官方
称为 Display Mark Word. 然后线程尝试使用 CAS 将对象头中的 Mark Word 替换为指向锁记录的指针. 成功：当前线程获取锁，失败，则自旋获取锁，
所以轻量级锁适用于线程间竞争时间极短的情况，如果说原本就知道线程竞争锁的时间很长，则可以通过参数禁止偏向锁和轻量级锁.


处理器是如何实现原子操作了？
1.可以通过缓存加锁或总线加锁的方式实现多处理器间的原子操作.

Java 中是如何实现原子操作了？

CAS.


关于 JDK 层面的 Lock 是如何实现的了？

volatile + cas.


内存屏障：

LoadLoad:
    Load1; LoadLoad; Load2 保证 Load1 指令在 Load2 及其后续指令加载前完成加载   
StoreStore:
    Store1; StoreStore; Store2 保证 Store1 指令对其他处理器可见，先于 Store2 指令及其后续存储指令的存储
LoadStore:
    Load1; LoadStore; Store2 保证 Load1 指令装载，先于 Store1 指令及其后续存储指令刷新进入主内存 
StoreLoad:
    Store1; StoreLoad; Load1 保证 Store1 指令对其他处理器可见，之前于 Load1 及后续装载指令的装载


volatile 内存语义：
在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；
在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；


参考：
    ① https://blog.csdn.net/xiaowenmu1/article/details/89705740