1.ConcurrentHashMap 的实现原理和使用

ConcurrentHashMap 是线程安全 Map. 为啥不用 HashTable 了？因为 HashTable 效率太低了，比如说在进行 put 操作的时候，read 操作就
用不了，所以一个很正常的思路就是：将数据分段，你加锁就加锁一个段的数据，这样对其他段就没有影响.

可能有的小伙伴会问？为啥不使用 HashMap 了？HashMap 在并发编程中，可能导致程序死循环. 在多线程环境下，使用 HashMap 进行 put 操作会
引起死循环，导致 CPU 利用率接近 100%.

为啥会引起死循环了？

发生死循环的原因在于 transfer 方法.

比如说原来 HashMap 中桶1 的位置存放的是这样的数据：3 -> 7 -> 5.

现在 A、B 两个线程都要向这个 HashMap 中插入数据，由于 HashMap 的容量达到阈值，需要进行扩容，在扩容的时候，是不是要将原 HashMap 中
的值转移到新数组中去？

现在假设线程A执行 transfer 方法的这段代码时挂起了：

Entry<K,V> next = e.next; // 此时 e = 3, next = 7.

现在由线程B进行执行：

线程B在执行的过程中，需要重新定位各个元素在新数组中的位置，假设桶1的位置存放5，桶3的位置存放 7-> 3.

这里的顺序是倒过来的，怎么理解了？

do {
  Entry<K,V> next = e.next; //假设线程一执行至此被挂起，执行线程二
  int i = indexFor(e.hash, newCapacity);
  e.next = newTable[i];
  newTable[i] = e;
   e = next;
} while (e != null);

看上面的那段代码，你会发现遍历链表的时候是从桶的位置开始遍历的，所以越靠近桶位置的元素，在转换到新数组中时，会离桶越远.

假设线程B执行完后，各个元素的位置如上面所描述的那样. 现在轮到 A 执行了，e = 3，next = 7. e = next(7), next = e.next(3)

这不就造成了死循环吗？3 -> 7 -> 3 -> 7 ...

当产生死循环后，如果调用 get 方法，将会陷入死循环，CPU 占用率高达 100%.


现在说下 ConcurrentHashMap 为啥高效了？因为 ConcurrentHashMap 采用了锁分段技术，相比较 HashTable 而言，HashTable 对整个数据
集进行了加锁，当一个线程A进行 put 操作时，其他线程进行读操作(但是被墙在外面，要等到线程A操作结束后，才能竞争锁访问)，这样其效率大大
降低了.

那 ConcurrentHashMap 是如何避免 HashTable 的弊端的了？

下面说下 ConcurrentHashMap 的数据结构.

ConcurrentHashMap 是由 Segment 数组和 HashEntry 数组组成. Segment 是一种可重入锁，HashEntry 则用于存储键值对. 一个 
ConcurrentHashMap 包含一个 Segment 数组，Segment 的结构和 HashMap 的结构很类似，是一种数组 + 链表的结构(即：一个 Segment
结构包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素)，每个 Segment 守护着一个 HashEntry 数组里的元素，当对
HashEntry 数组的数据进行修改时，必须首先获得与它对应的 Segment 锁.

现在再说的直白点，以前 HashTable 相当于一个 Segment 的结构. 现在 ConcurrentHashMap 相当于多个 HashTable. 在操作不同的 Segment
的时候，不影响其他 Segment.

通过阅读 ConcurrentHashMap 的构造方法，总结如下：
(1)segment 数组的长度 ssize 是通过 concurrencyLevel 计算来的. 为了能通过按位 & 来定位 segments 数组的索引，必须保证 ssize 的
长度为 2 的 N 次方. concurrencyLevel 的最大值为 65535.
(2)sshift 为 1 左移多少位到 ssize.
(3)segmentShift 等于 32 - sshift
(4)segmentMask 是散列运算的掩码，为 ssize - 1


2.下面来看下 ConcurrentHashMap 的操作

(1)get 操作，get 操作实现非常简单，先经过一次再散列，然后使用这个散列值通过散列运算定位到 Segment，在通过算列算法定位到元素. 整个
过程高效，为啥高效了？因为 Segment 中 HashEntry 数组是使用 volatile 修饰的，它能够在线程间保持可见性，能够被多线程同时读，并且
保证不会读到过期的值.


参考：jianshu.com/p/4930801e23c8

